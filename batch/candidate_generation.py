# simplers/batch/candidate_generation.py
import logging
import pandas as pd
from dask import delayed, compute
from typing import Dict, Any, List
import sys
import traceback
from datetime import datetime
import signal
import os

# ë°ì´í„° ë¡œë”© ë° DB ê´€ë¦¬ í•¨ìˆ˜
from batch.utils.db_manager import (
    load_users, load_contents, save_results,
    get_mongo_db, get_os_client, get_oracle_pool,
    close_mongo, close_opensearch, close_oracle,
    MongoDBError, OpenSearchError, DataIntegrityError
)
# ë¡œê¹… ì„¤ì •
from batch.utils.logging_setup import setup_logging
from batch.utils.config_loader import MAX_CANDIDATES_PER_USER
# íŒŒì´í”„ë¼ì¸ í•¨ìˆ˜
from batch.pipeline.global_candidate import compute_global_candidates
from batch.pipeline.final_candidate import generate_candidate_for_user
# ë°ì´í„° ë¡œë”
from batch.utils.data_loader import load_user_interactions, APIConnectionError, DataValidationError

# --- ë¡œê¹… ì„¤ì • ---
setup_logging()
logger = logging.getLogger(__name__)

class BatchProcessError(Exception):
    """ë°°ì¹˜ í”„ë¡œì„¸ìŠ¤ ê´€ë ¨ ì˜ˆì™¸"""
    pass

class BatchInterruptedError(BatchProcessError):
    """ë°°ì¹˜ í”„ë¡œì„¸ìŠ¤ ì¤‘ë‹¨ ì˜ˆì™¸"""
    pass

# ì „ì—­ ë³€ìˆ˜ë¡œ ì •ë¦¬ ì‘ì—… ì¶”ì 
cleanup_performed = False

def signal_handler(signum, frame):
    """ì‹œê·¸ë„ í•¸ë“¤ëŸ¬ - ë°°ì¹˜ í”„ë¡œì„¸ìŠ¤ ì•ˆì „ ì¢…ë£Œ"""
    global cleanup_performed
    
    logger.warning(f"Received signal {signum}. Initiating graceful shutdown...")
    
    if not cleanup_performed:
        cleanup_resources()
        cleanup_performed = True
    
    logger.info("Graceful shutdown completed.")
    sys.exit(1)

def cleanup_resources():
    """ë¦¬ì†ŒìŠ¤ ì •ë¦¬ í•¨ìˆ˜"""
    try:
        logger.info("Cleaning up database connections...")
        close_mongo()
        close_opensearch() 
        close_oracle()
        logger.info("Resource cleanup completed.")
    except Exception as e:
        logger.error(f"Error during resource cleanup: {e}")

def validate_environment():
    """ì‹¤í–‰ í™˜ê²½ ê²€ì¦"""
    logger.info("Validating execution environment...")
    
    # í•„ìˆ˜ í™˜ê²½ ë³€ìˆ˜ ì²´í¬
    required_env_vars = []  # í•„ìš”ì‹œ ì¶”ê°€
    missing_vars = [var for var in required_env_vars if not os.getenv(var)]
    
    if missing_vars:
        raise BatchProcessError(f"Missing required environment variables: {missing_vars}")
    
    # ë©”ëª¨ë¦¬ ì²´í¬ (ê°„ë‹¨í•œ ì²´í¬)
    try:
        import psutil
        memory = psutil.virtual_memory()
        if memory.available < 1024 * 1024 * 1024:  # 1GB ë¯¸ë§Œ
            logger.warning(f"Low available memory: {memory.available / (1024**3):.2f}GB")
    except ImportError:
        logger.debug("psutil not available for memory check")
    
    logger.info("Environment validation completed.")

def main():
    """ë©”ì¸ ë°°ì¹˜ í”„ë¡œì„¸ìŠ¤ í•¨ìˆ˜"""
    # ì‹œê·¸ë„ í•¸ë“¤ëŸ¬ ë“±ë¡
    signal.signal(signal.SIGINT, signal_handler)
    signal.signal(signal.SIGTERM, signal_handler)
    
    logger.info("=" * 80)
    logger.info("Starting candidate generation batch process...")
    logger.info(f"Process started at: {datetime.now()}")
    logger.info("=" * 80)
    
    start_time = pd.Timestamp.now()
    db = None
    final_results_to_save = []
    success = False

    try:
        # í™˜ê²½ ê²€ì¦
        validate_environment()
        
        # --- DB ì—°ê²° ---
        logger.info("Establishing database connections...")
        try:
            db = get_mongo_db()
            os_client = get_os_client()
            oracle_pool = get_oracle_pool()
            logger.info("All database connections established successfully.")
        except (MongoDBError, OpenSearchError) as e:
            logger.error(f"Database connection failed: {e}")
            raise BatchProcessError(f"Failed to establish database connections: {e}")

        # --- ê¸°ë³¸ ë°ì´í„° ë¡œë”© ---
        logger.info("Loading base data from MongoDB...")
        try:
            users_ddf = load_users(db)
            contents_ddf = load_contents(db)
        except Exception as e:
            logger.error(f"Failed to load base data: {e}")
            raise BatchProcessError(f"Base data loading failed: {e}")

        # --- ë°ì´í„° ë³€í™˜ ë° ê²€ì¦ ---
        logger.info("Computing base data to Pandas...")
        try:
            users_pd = users_ddf.compute()
            contents_list = contents_ddf.compute().to_dict('records')
            
            if users_pd.empty:
                raise BatchProcessError("No users found in database")
            
            if not contents_list:
                raise BatchProcessError("No contents found in database")
                
            all_content_ids = [c['id'] for c in contents_list]
            logger.info(f"Loaded {len(users_pd)} users and {len(contents_list)} contents into memory.")
            
        except Exception as e:
            logger.error(f"Data computation failed: {e}")
            raise BatchProcessError(f"Failed to compute base data: {e}")

        # --- ì´ˆê¸° ì»¨í…ìŠ¤íŠ¸ ìƒì„± ---
        logger.info("Creating base context...")
        try:
            base_context: Dict[str, Any] = {
                'contents_list': contents_list,
                'content_meta_map': {c.get('_id', c.get('id')): c for c in contents_list},
                'mongo_db': db,
                'os_client': os_client,
                'oracle_pool': oracle_pool,
                'max_candidates_per_user': MAX_CANDIDATES_PER_USER,
            }
            logger.info("Base context created successfully.")
        except Exception as e:
            logger.error(f"Context creation failed: {e}")
            raise BatchProcessError(f"Failed to create base context: {e}")

        # --- ê¸€ë¡œë²Œ í›„ë³´ ìƒì„± ---
        logger.info("Generating global candidates...")
        try:
            global_candidates = compute_global_candidates(base_context)
            logger.info(f"Generated {len(global_candidates)} global candidates")
        except Exception as e:
            logger.error(f"Global candidate generation failed: {e}")
            # ê¸€ë¡œë²Œ í›„ë³´ ì‹¤íŒ¨ëŠ” ì¹˜ëª…ì ì´ì§€ ì•ŠìŒ
            global_candidates = []
            logger.warning("Continuing with empty global candidates")

        # --- ê¸°íƒ€ í›„ë³´ ìƒì„± ---
        logger.info("Generating other candidates...")
        try:
            from batch.rules.global_rules import GlobalTopLikedContentRule
            other_rule = GlobalTopLikedContentRule()
            other_candidates = other_rule.apply(base_context)
            logger.info(f"Generated {len(other_candidates)} other candidates")
        except Exception as e:
            logger.error(f"Other candidate generation failed: {e}")
            # ê¸°íƒ€ í›„ë³´ ì‹¤íŒ¨ëŠ” ì¹˜ëª…ì ì´ì§€ ì•ŠìŒ
            other_candidates = []
            logger.warning("Continuing with empty other candidates")

        # --- ì‚¬ìš©ìë³„ ìµœì¢… í›„ë³´ ìƒì„± ---
        logger.info(f"Generating final candidates and scores for {len(users_pd)} users...")
        try:
            delayed_results = []
            for _, user_row in users_pd.iterrows():
                user_dict = user_row.to_dict()
                delayed_result = delayed(generate_candidate_for_user)(
                    user_dict, global_candidates, other_candidates, base_context
                )
                delayed_results.append(delayed_result)

            if delayed_results:
                logger.info("Computing delayed results...")
                computed_results = compute(*delayed_results)
                final_results_to_save = [res for res in computed_results if res and res.get('curation_list')]
                logger.info(f"Computed results for {len(computed_results)} users. "
                          f"Found {len(final_results_to_save)} users with valid candidates.")
            else:
                logger.warning("No users to process for final candidate generation.")
                final_results_to_save = []
                
        except Exception as e:
            logger.error(f"Final candidate generation failed: {e}")
            raise BatchProcessError(f"Failed to generate final candidates: {e}")

        # --- ê²°ê³¼ ì €ì¥ ---
        logger.info("Saving final results...")
        if final_results_to_save:
            try:
                save_success = save_results(final_results_to_save, db, collection_name="user_candidate")
                if save_success:
                    success = True
                    logger.info("Results saved successfully to MongoDB")
                else:
                    logger.warning("Results saved to fallback file only")
            except (MongoDBError, DataIntegrityError) as e:
                logger.error(f"Failed to save results: {e}")
                raise BatchProcessError(f"Result saving failed: {e}")
        else:
            logger.warning("No final results generated to save.")
            success = True  # ê²°ê³¼ê°€ ì—†ëŠ” ê²ƒë„ ì„±ê³µìœ¼ë¡œ ê°„ì£¼

    except BatchProcessError as e:
        logger.critical(f"Batch process error: {e}")
        success = False
        
    except (MongoDBError, OpenSearchError, DataIntegrityError) as e:
        logger.critical(f"Database error: {e}")
        success = False
        
    except (APIConnectionError, DataValidationError) as e:
        logger.critical(f"External API error: {e}")
        success = False
        
    except KeyboardInterrupt:
        logger.warning("Batch process interrupted by user")
        success = False
        
    except Exception as e:
        logger.critical(f"Unexpected error during candidate generation process: {e}", exc_info=True)
        success = False

    finally:
        # --- ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ---
        if not cleanup_performed:
            cleanup_resources()

        # --- ìµœì¢… ê²°ê³¼ ë¡œê¹… ---
        end_time = pd.Timestamp.now()
        total_duration = (end_time - start_time).total_seconds()
        
        logger.info("=" * 80)
        if success:
            logger.info("âœ… BATCH PROCESS COMPLETED SUCCESSFULLY")
            logger.info(f"ğŸ“Š Processed {len(final_results_to_save)} users with candidates")
        else:
            logger.error("âŒ BATCH PROCESS FAILED")
            
        logger.info(f"â±ï¸  Total duration: {total_duration:.2f} seconds")
        logger.info(f"ğŸ• Process ended at: {datetime.now()}")
        logger.info("=" * 80)
        
        # ì‹¤íŒ¨ ì‹œ exit code 1ë¡œ ì¢…ë£Œ
        if not success:
            sys.exit(1)

if __name__ == '__main__':
    main()
